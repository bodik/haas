# HaaS - Honeypot as a Service -- Packaging and basic cluster management for flab.cesnet.cz honeypots

This software suite is designed to aid creating and maintaining cluster of
honeypots with warden transport.  It is based on masterless puppet and bash
automation.

### Acknowledgement

Computational resources were provided by the MetaCentrum under the program
LM2010005 and the CERIT-SC under the program Centre CERIT Scientific Cloud,
part of the Operational Program Research and Development for Innovations, Reg.
no. CZ.1.05/3.2.00/08.0144.



## Introduction

HaaS is project to create develompment and build environment for generating
honeypot VMs.

Based on [Warden project](https://warden.cesnet.cz) -- a system for efficient
sharing information about detected events (threats). Warden is a part of the
CESNET Large Infrastructure project developed by the [CESNET
association](https://www.cesnet.cz). The system enables CERTS/CSIRT teams (and
security teams in general) to share and make use of information on detected
anomalies in network and services operation generated by different systems –
IDS, honeypots, network probes, traffic logs, etc. – easily and efficiently.

HaaS uses masterless puppet, python, bash and Jenkins to generate VMs with
various preinstalled honeypots enabled for running and reporting to central
information exchange server.



## Basic honeypot node installation

- download VM ova image from [TODO:repository](TODO), import VM into virtualization platform and run it
- login to VM using default credentials `root:debian`

- generate host certificate
```
sh /puppet/warden3/bin/haas_init.sh
```
- let Warden acknowleded certification authority sign it and place result under `/opt/hostcert/<FQDN>.crt`

- [get client registered](https://warden.cesnet.cz/en/participation#registration) at Warden server

- finalize VM configuration
```
sh /puppet/warden3/bin/haas_finalize.sh
```

- reboot VM



## Development information

Masterless puppet ecoystem is split into set of components installable on
almost any Debian 9.x Stretch VM.

### Components

Each major component should provide a puppet module and set of install/check
and other scripts within itself.

```
component/			-- puppet module
component/fileX			-- additional file (perhaps a script)
component/tests/componentX.sh	-- simple test checking real state of the service
  				   typically used by jenkins autotests

component.install.sh		-- script for masterless installation
component.check.sh		-- script for state detection (noop show_diff)
```

### Usecases

#### Ops/Maintenance

Bootstrap suite from a git repository, subsequent calls will pull from master repo.

```
wget esb.metacentrum.cz/haas.git/bootstrap.install.sh && sh bootstrap.install.sh
cd /puppet && ls -l
sh bootstrap.install.sh
```

During ops, components/roles can be installed on managed node or the state of
installed component can be checked by component selftest or puppet itself.

```
sh componentX.install.sh 		## install a component
sh component/tests/component.sh		## run a component selftest

pa.sh -e 'class {"glog::glog2": }'	## use component directly by puppet
```

Lately, a state of node can change, perhaps by rutime tuning or more
development. A `check_stddev.sh` can be used to check changed things within the
system. All available component's .check.sh will be called.

```
sh check_stddev.sh
```

Changes can be accepted into repository or node state could be reverted to origial state.

``` 
cp /etc/fileX component/templates/fileX
vim component/manifests/subclass.pp
sh check_stddev.sh
git status
git commit
```

#### Example installation of ELK analytics node

Following commands will ensure installation of basic components for data analysis.
(elasticsearch data node, logstash processor, kibana frontend).

```
wget esb.metacentrum.cz/rsyslog2.git/bootstrap.install.sh && sh bootstrap.install.sh
cd /puppet && ls -l
sh phase2.install.sh
sh glog2.install.sh
sh glog/tests/glog2.sh
links https://$(facter fqdn)/haas/test/dash.html
```
 
#### Example installation of testing warden-server development node

Commands will ensure installation of all components needed for running basic
warden-server node along with warden_ca and glog2 analytics.

```
wget esb.metacentrum.cz/haas.git/bootstrap.install.sh && sh bootstrap.install.sh
cd /puppet && ls -l
sh phase2.install.sh
sh metalib/tests/phase2.sh

sh lamp.install.sh
sh lamp/tests/lamp.sh
sh warden3-server.install.sh
sh warden3/tests/server.sh
sh glog2.install.sh
sh glog/tests/glog2.sh
```

### Automating tasks with (Robert) Jenkins

While maintaining a small site can be done by hand as shown in previous
chapter, large environment can use modules/components through standard
puppetmaster, but neither approach is suitable for fast development iterations
or creating an ad-hoc experiment environment (like performance or acceptance
testing).

Sometimes a more complex tasks are needed to be automated -- eg. creating an
rsyslog server, 2 clients, spawning a test and archiving outputs and artefacts
for latter use. In our case Jenkins is runing on private VM, equiped with
user's credentials and performing tasks towards available clouds and
provisioned VMs. More documentation can be found in separate Jenkins component
documentation.

### Available components

* [metalib](metalib/)
  * [iptables](iptables/)
* [jenkins](jenkins/)
* [lamp](lamp/)
* [gmysql](gmysql/)
* [glog2](glog2/)
* [warden3-server](warden3/)
  * [warden3-tologstash](warden3/)
  * [hpcowrie](hpcowrie/)
  * [hpdio](hpcowrie/)
  * [hptelnetd](hptelnetd/)
  * [hpucho](hpucho/)
  * [hpjdwpd](hpjdwpd/)

